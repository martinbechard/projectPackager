/**
 * Copyright (c) 2024 Martin Bechard <martin.bechard@DevConsult.ca>
 * This software is licensed under the MIT License.
 * File: scripts/projectPackager.js
 * This was generated by Claude Sonnet 3.5, with the assistance of my human mentor
 * Summary: Utility script for packaging project files
 * Witty remark: Packaging your code tighter than a hipster's skinny jeans!
 */

const fs = require("fs");
const path = require("path");
const yargs = require("yargs/yargs");
const { hideBin } = require("yargs/helpers");
const { execSync } = require("child_process");

let config = null;
let argv = null;

/**
 * Loads the configuration from the specified JSON file
 * @param {string} configPath - Path to the configuration file
 * @throws {Error} If the configuration file cannot be read or parsed
 */
const loadConfig = (configPath) => {
  try {
    const configContent = fs.readFileSync(configPath, "utf8");
    config = JSON.parse(configContent);
  } catch (error) {
    throw new Error(`Failed to load config file: ${error.message}`);
  }
};

/**
 * Retrieves the current configuration
 * @returns {Object} The current configuration object
 */
const getConfig = () => config;

/**
 * Gets the file type configuration for a given file
 * @param {string} filePath - Path to the file
 * @param {Object} config - Configuration object with fileTypes
 * @returns {Object} The file type configuration
 */
const getFileTypeConfig = (filePath, config) => {
  const ext = path.extname(filePath);
  const fileType = Object.entries(config.fileTypes).find(([_, typeConfig]) =>
    typeConfig.extensions.includes(ext)
  );

  return fileType ? fileType[1] : config.fileTypes.js; // default to js config if unknown
};

/**
 * Checks if this is an excluded file
 * @param {string} filePath - Path to the file
 * @param {Object} typeConfig - File type configuration
 * @returns {boolean} True if this file should be excluded
 */
const isExcludedFile = (filePath, typeConfig) => {
  return typeConfig.exclude?.includes(path.basename(filePath)) || false;
};

/**
 * Gets the initial comment block from a file content based on its config
 * @param {string} content - Content of the file
 * @param {Object} typeConfig - File type configuration
 * @returns {string|Object|null} The comment block or null if none found
 */
const getInitialComment = (content, typeConfig) => {
  if (typeConfig.style === "json") {
    try {
      const json = JSON.parse(content);
      const hasAttributes = typeConfig.attributes.some((attr) => attr in json);
      return hasAttributes ? json : null;
    } catch {
      return null;
    }
  }

  const prefix = typeConfig.prefix.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
  const suffix = typeConfig.suffix.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
  const commentMatch = content.match(
    new RegExp(`^\\s*${prefix}[\\s\\S]*?${suffix}`)
  );
  return commentMatch ? commentMatch[0] : null;
};

/**
 * Updates an existing comment to ensure it has required lines
 * @param {string|Object} comment - The existing comment
 * @param {string} filePath - Path to the file
 * @param {Object} typeConfig - File type configuration
 * @returns {string} The updated comment
 */
const updateExistingComment = (comment, filePath, typeConfig) => {
  const config = getConfig();

  if (typeConfig.style === "json") {
    // comment is already a parsed JSON object for JSON files
    const json = typeof comment === "string" ? JSON.parse(comment) : comment;
    if (!json._copyright) json._copyright = config.copyright;
    if (!json._license)
      json._license = "This software is licensed under the MIT License.";
    if (!json._file || json._file !== filePath) json._file = filePath;
    return JSON.stringify(json, null, 2);
  }

  const lines = comment.split("\n");
  let hasCopyright = false;
  let hasLicense = false;
  let hasFile = false;

  // Check existing lines and update file path if it exists
  lines.forEach((line, index) => {
    if (line.includes("Copyright")) hasCopyright = true;
    if (line.includes("License")) hasLicense = true;
    if (line.includes("File:")) {
      hasFile = true;
      lines[index] = `${
        typeConfig.linePrefix || ""
      } File: ${filePath}`.trimRight();
    }
  });

  // Find insertion point (after prefix line)
  const insertIndex =
    lines.findIndex((line) => line.trim().startsWith(typeConfig.prefix)) + 1;

  // Add missing lines
  if (!hasFile) {
    const fileLine = typeConfig.linePrefix
      ? `${typeConfig.linePrefix} File: ${filePath}`
      : `File: ${filePath}`;
    lines.splice(insertIndex, 0, fileLine);
  }
  if (!hasLicense) {
    const licenseLine = typeConfig.linePrefix
      ? `${typeConfig.linePrefix} This software is licensed under the MIT License.`
      : "This software is licensed under the MIT License.";
    lines.splice(insertIndex, 0, licenseLine);
  }
  if (!hasCopyright) {
    const copyrightLine = typeConfig.linePrefix
      ? `${typeConfig.linePrefix} ${config.copyright}`
      : config.copyright;
    lines.splice(insertIndex, 0, copyrightLine);
  }

  return lines.join("\n");
};

/**
 * Generates a complete new header for a file
 * @param {string} filePath - Path to the file
 * @param {Object} typeConfig - File type configuration
 * @param {string} content - Original file content
 * @returns {string} The generated header with content
 */
const generateCompleteHeader = (filePath, typeConfig, content) => {
  const config = getConfig();
  const aiAttrib =
    config.aiAttribution ||
    "This was generated by Claude Sonnet 3.5, with the assistance of my human mentor";

  if (typeConfig.style === "json") {
    try {
      const existingContent = JSON.parse(content);
      return JSON.stringify(
        {
          _copyright: config.copyright,
          _license: "This software is licensed under the MIT License.",
          _file: filePath,
          ...existingContent,
        },
        null,
        2
      );
    } catch {
      return content; // Return unchanged if JSON parsing fails
    }
  }

  const lines = [
    config.copyright,
    "This software is licensed under the MIT License.",
    `File: ${filePath}`,
    aiAttrib,
  ];

  // Generate the header
  let header;
  if (!typeConfig.linePrefix) {
    // For styles without line prefixes (markdown, html, python)
    header = `${typeConfig.prefix}\n${lines.join("\n")}\n${
      typeConfig.suffix
    }\n\n`;
  } else {
    // For styles with line prefixes (js, css)
    header = `${typeConfig.prefix}\n${lines
      .map((line) => `${typeConfig.linePrefix} ${line}`)
      .join("\n")}\n${typeConfig.suffix}\n\n`;
  }

  // Remove any existing header from the content
  const contentWithoutHeader = content
    .replace(/^\/\*\*[\s\S]*?\*\/\s*/, "")
    .replace(/^\/\*[\s\S]*?\*\/\s*/, "")
    .replace(/^<!--[\s\S]*?-->\s*/, "")
    .replace(/^"""[\s\S]*?"""\s*/, "");

  // Return header followed by the content
  return header + contentWithoutHeader;
};

/**
 * Adds or corrects the header of a file
 * @param {string} filePath - Path to the file
 * @param {string} content - Content of the file
 * @returns {string} The content with the correct header
 */
const addOrCorrectHeader = (filePath, content) => {
  const config = getConfig();
  const typeConfig = getFileTypeConfig(filePath, config);

  // Skip excluded files
  if (isExcludedFile(filePath, typeConfig)) {
    return content;
  }

  const initialComment = getInitialComment(content, typeConfig);
  if (!initialComment) {
    return generateCompleteHeader(filePath, typeConfig, content);
  }

  // Update existing header
  const updatedComment = updateExistingComment(
    initialComment,
    filePath,
    typeConfig
  );
  if (typeConfig.style === "json") {
    return updatedComment;
  }

  // Get the content after the initial comment
  const remainingContent = content.substring(initialComment.length);
  // Return updated header followed by the remaining content
  return updatedComment + remainingContent;
};

/**
 * Recursively gets all files in a directory
 * @param {string} dir - The directory to search
 * @returns {string[]} An array of file paths
 */
const getAllFiles = (dir) => {
  const files = fs.readdirSync(dir);
  let allFiles = [];
  for (const file of files) {
    const filePath = path.join(dir, file);
    if (fs.statSync(filePath).isDirectory()) {
      if (!config.skipFolders.includes(file)) {
        allFiles = allFiles.concat(getAllFiles(filePath));
      }
    } else {
      const ext = path.extname(file);
      // Check if this extension is handled by any file type
      const isHandled = Object.values(config.fileTypes).some((typeConfig) =>
        typeConfig.extensions.includes(ext)
      );
      if (isHandled) {
        allFiles.push(filePath);
      }
    }
  }
  return allFiles;
};

/**
 * Gets the grouping folder path based on maxNestingLevel
 * @param {string} filePath - The full path of the file
 * @param {string} basePath - The base output path
 * @param {number} maxNestingLevel - Maximum nesting level for grouping
 * @returns {string} The grouping folder path
 */
const getGroupingFolder = (filePath, basePath, maxNestingLevel) => {
  const relativePath = path.relative(basePath, filePath);
  const parts = relativePath.split(path.sep);

  if (parts.length <= maxNestingLevel) {
    return path.dirname(relativePath);
  }

  return parts.slice(0, maxNestingLevel).join(path.sep);
};

/**
 * Creates a backup of a file
 * @param {string} filePath - Path to the file to backup
 */
const backupFile = (filePath) => {
  const backupDir = path.join(config.outputFolder, config.backupFolder);
  if (!fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true });
  }
  const backupPath = path.join(backupDir, path.basename(filePath));
  fs.copyFileSync(filePath, backupPath);
};

/**
 * Concatenates files by their folder up to maxNestingLevel
 * @param {Object} config - The project packager configuration
 * @param {string} tempDir - Directory containing processed files
 * @param {string} outputPath - Final output directory for markdown files
 * @returns {Promise<void>}
 */
const concatenateOutputFiles = async (config, tempDir, outputPath) => {
  const allFiles = getAllFiles(tempDir);
  const maxNestingLevel = config.maxNestingLevel || 1;

  // Group files by their folder up to maxNestingLevel
  const filesByFolder = {};
  for (const file of allFiles) {
    const groupingFolder = getGroupingFolder(file, tempDir, maxNestingLevel);

    if (!filesByFolder[groupingFolder]) {
      filesByFolder[groupingFolder] = [];
    }
    filesByFolder[groupingFolder].push(file);
  }

  // Create output directory if it doesn't exist
  if (!fs.existsSync(outputPath)) {
    fs.mkdirSync(outputPath, { recursive: true });
  }

  // Create concatenated markdown file for each folder group
  for (const [folder, files] of Object.entries(filesByFolder)) {
    const concatenatedContent = [];
    const folderName = folder === "." ? "root" : folder;

    // Add folder title
    concatenatedContent.push(`# ${folderName}\n`);

    // Sort files to ensure consistent output
    files.sort((a, b) => a.localeCompare(b));

    for (const file of files) {
      const relativePath = path.relative(tempDir, file);
      const content = fs.readFileSync(file, "utf8");
      const extension = path.extname(file).slice(1); // remove the dot

      concatenatedContent.push(`## ${relativePath}\n`);
      concatenatedContent.push("```" + extension);
      concatenatedContent.push(content);
      concatenatedContent.push("```\n");
    }

    // Create sanitized folder name for the output file
    const sanitizedFolderName = folderName.replace(/[\/\\]/g, "-");
    const concatenatedPath = path.join(outputPath, `${sanitizedFolderName}.md`);
    fs.writeFileSync(concatenatedPath, concatenatedContent.join("\n"));

    // Log the creation
    console.log(
      `Created markdown file for ${folderName} at ${concatenatedPath}`
    );
  }
};

/**
 * Packages the project files
 */
const packageProject = async (args) => {
  console.log("Starting packageProject");
  const files = getAllFiles(process.cwd());
  const outputPath = path.join(process.cwd(), config.outputFolder);

  // Create temporary directory for processing if not expanding
  const tempDir = args.expand ? outputPath : path.join(outputPath, ".temp");

  console.log(`Found ${files.length} files to package`);

  // First, process all files individually
  files.forEach((file) => {
    console.log(`Processing file: ${file}`);
    const content = fs.readFileSync(file, "utf8");
    const packagedContent = addOrCorrectHeader(file, content);
    const outputFilePath = path.join(
      tempDir,
      path.relative(process.cwd(), file)
    );
    console.log(`Writing to: ${outputFilePath}`);
    fs.mkdirSync(path.dirname(outputFilePath), { recursive: true });
    fs.writeFileSync(outputFilePath, packagedContent);
  });

  // Then concatenate all files from the temporary directory
  await concatenateOutputFiles(config, tempDir, outputPath);

  // Clean up temporary directory if not expanding
  if (!args.expand) {
    if (fs.existsSync(tempDir)) {
      fs.rmSync(tempDir, { recursive: true, force: true });
    }
  }

  console.log("Project packaged and concatenated successfully.");
};

/**
 * Extracts a file's content from markdown code block
 * @param {string} block - The markdown code block content
 * @returns {{extension: string, content: string}} The file extension and content
 */
const extractFromCodeBlock = (block) => {
  const firstLine = block.split("\n")[0];
  const extension = firstLine.trim();
  const content = block.split("\n").slice(1).join("\n");
  return { extension, content };
};

/**
 * Processes a markdown file and extracts its files
 * @param {string} markdownPath - Path to the markdown file
 * @param {string} baseOutputPath - Base path for output files
 * @returns {Array<{path: string, content: string}>} Array of extracted files
 */
const processMarkdownFile = (markdownPath) => {
  const content = fs.readFileSync(markdownPath, "utf8");
  const files = [];

  // Get base folder name from markdown file name
  const baseFolderName = path.basename(markdownPath, ".md");
  const baseFolder =
    baseFolderName === "root" ? "." : baseFolderName.replace(/-/g, "/");

  // Split content into sections by ## headers
  const sections = content.split("\n## ");

  // Skip the first section as it's the # folder title
  for (let i = 1; i < sections.length; i++) {
    const section = sections[i];
    const lines = section.split("\n");

    // First line is the file path
    const relativePath = lines[0].trim();

    // Find the code block
    const codeBlockStart = lines.findIndex((line) => line.startsWith("```"));
    if (codeBlockStart === -1) continue;

    const codeBlockEnd =
      lines
        .slice(codeBlockStart + 1)
        .findIndex((line) => line.startsWith("```")) +
      codeBlockStart +
      1;
    if (codeBlockEnd === -1) continue;

    const codeBlock = lines.slice(codeBlockStart + 1, codeBlockEnd).join("\n");
    const { content } = extractFromCodeBlock(codeBlock);

    // Calculate the full path relative to the base folder
    const fullPath =
      baseFolder === "." ? relativePath : path.join(baseFolder, relativePath);

    files.push({ path: fullPath, content });
  }

  return files;
};

/**
 * Modified unpackageProject function that works with markdown format
 * @param {Object} args - Command line arguments
 */
const unpackageProject = async (args) => {
  console.log("Starting unpackageProject");
  const packagedFolder = path.join(process.cwd(), config.outputFolder);
  const outputBase = process.cwd();
  const tempDir = args.expand
    ? path.join(packagedFolder)
    : path.join(packagedFolder, ".temp");

  if (!fs.existsSync(packagedFolder)) {
    console.error(`Package folder ${packagedFolder} does not exist`);
    process.exit(1);
  }

  // Find all markdown files
  const markdownFiles = fs
    .readdirSync(packagedFolder)
    .filter((file) => file.endsWith(".md"))
    .map((file) => path.join(packagedFolder, file));

  console.log(`Found ${markdownFiles.length} markdown files to process`);

  // Process each markdown file
  for (const mdFile of markdownFiles) {
    console.log(`Processing ${mdFile}...`);
    const files = processMarkdownFile(mdFile);

    // Write each file
    for (const { path: filePath, content } of files) {
      // Write to original location
      const originalPath = path.join(outputBase, filePath);
      console.log(`Writing to: ${originalPath}`);
      fs.mkdirSync(path.dirname(originalPath), { recursive: true });
      fs.writeFileSync(originalPath, content);

      // If expand is true, also write to package directory
      if (args.expand) {
        const packagePath = path.join(tempDir, filePath);
        console.log(`Writing to package: ${packagePath}`);
        fs.mkdirSync(path.dirname(packagePath), { recursive: true });
        fs.writeFileSync(packagePath, content);
      }
    }
  }

  console.log("Project unpackaged successfully.");
};

/**
 * Runs the project tests
 * @param {boolean} watch - Whether to run tests in watch mode
 */
const runTests = (watch = true) => {
  try {
    console.log(watch ? "Running tests in watch mode..." : "Running tests...");
    const watchFlag = watch ? "--watch" : "";
    const jestCommand = `jest ${watchFlag} --testPathPattern=projectPackager`;
    execSync(jestCommand, { stdio: "inherit" });
    console.log("Test run completed successfully.");
  } catch (error) {
    console.error("Some tests failed.");
    process.exit(1);
  }
};

/**
 * Parses command line arguments
 * @returns {Object} Parsed arguments
 */
const parseArgs = () => {
  // Reset argv to ensure fresh parsing each time
  argv = null;
  return yargs(hideBin(process.argv))
    .option("verbose", {
      alias: "v",
      type: "boolean",
      description: "Run with verbose logging",
    })
    .option("unpackage", {
      alias: "u",
      type: "boolean",
      description: "Unpackage previously packaged files",
    })
    .option("expand", {
      alias: "e",
      type: "boolean",
      default: false,
      description:
        "Expland the files being packaged into the ouptput directory",
    })
    .option("test", {
      alias: "t",
      type: "boolean",
      description: "Run unit tests",
    })
    .option("watch", {
      type: "boolean",
      default: true,
      description: "Run tests in watch mode",
    })
    .option("configPath", {
      type: "string",
      default:
        "/Users/martinbechard/dev/projectPackager/scripts/projectPackager.json",
      description: "Path to the configuration file",
    })
    .parse();
};

/**
 * Main function to run the project packager
 */
const main = () => {
  const args = parseArgs();
  loadConfig(args.configPath);

  if (args.test) {
    runTests(args.watch);
  } else if (args.unpackage) {
    unpackageProject();
  } else {
    packageProject(args);
  }
};

// Run the main function if this script is executed directly
if (require.main === module) {
  main();
}

module.exports = {
  loadConfig,
  getConfig,
  getFileTypeConfig,
  getInitialComment,
  generateCompleteHeader,
  updateExistingComment,
  addOrCorrectHeader,
  isExcludedFile,
  getAllFiles,
  getGroupingFolder,
  backupFile,
  packageProject,
  unpackageProject,
  runTests,
  parseArgs,
  main,
};
