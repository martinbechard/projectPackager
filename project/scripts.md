# scripts

## scripts/projectPackager.js

```js
/**
 * Copyright (c) 2024 Martin Bechard <martin.bechard@DevConsult.ca>
 * This software is licensed under the MIT License.
 * File: /Users/martinbechard/dev/projectPackager/scripts/projectPackager.js
 * This was generated by Claude Sonnet 3.5, with the assistance of my human mentor
 * Summary: Utility script for packaging project files
 * Witty remark: Packaging your code tighter than a hipster's skinny jeans!
 */

const fs = require("fs");
const path = require("path");
const yargs = require("yargs/yargs");
const { hideBin } = require("yargs/helpers");
const { execSync } = require("child_process");

let config = null;
let argv = null;

/**
 * Loads the configuration from the specified JSON file
 * @param {string} configPath - Path to the configuration file
 * @throws {Error} If the configuration file cannot be read or parsed
 */
const loadConfig = (configPath) => {
  try {
    const configContent = fs.readFileSync(configPath, "utf8");
    config = JSON.parse(configContent);
  } catch (error) {
    throw new Error(`Failed to load config file: ${error.message}`);
  }
};

/**
 * Retrieves the current configuration
 * @returns {Object} The current configuration object
 */
const getConfig = () => config;

/**
 * Gets the file type configuration for a given file
 * @param {string} filePath - Path to the file
 * @param {Object} config - Configuration object with fileTypes
 * @returns {Object} The file type configuration
 */
const getFileTypeConfig = (filePath, config) => {
  const ext = path.extname(filePath);
  const fileType = Object.entries(config.fileTypes).find(([_, typeConfig]) =>
    typeConfig.extensions.includes(ext)
  );

  return fileType ? fileType[1] : config.fileTypes.js; // default to js config if unknown
};

/**
 * Checks if this is an excluded file
 * @param {string} filePath - Path to the file
 * @param {Object} typeConfig - File type configuration
 * @returns {boolean} True if this file should be excluded
 */
const isExcludedFile = (filePath, typeConfig) => {
  return typeConfig.exclude?.includes(path.basename(filePath)) || false;
};

/**
 * Gets the initial comment block from a file content based on its config
 * @param {string} content - Content of the file
 * @param {Object} typeConfig - File type configuration
 * @returns {string|Object|null} The comment block or null if none found
 */
const getInitialComment = (content, typeConfig) => {
  if (typeConfig.style === "json") {
    try {
      const json = JSON.parse(content);
      const hasAttributes = typeConfig.attributes.some((attr) => attr in json);
      return hasAttributes ? json : null;
    } catch {
      return null;
    }
  }

  const prefix = typeConfig.prefix.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
  const suffix = typeConfig.suffix.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
  const commentMatch = content.match(
    new RegExp(`^\\s*${prefix}[\\s\\S]*?${suffix}`)
  );
  return commentMatch ? commentMatch[0] : null;
};

/**
 * Updates an existing comment to ensure it has required lines
 * @param {string|Object} comment - The existing comment
 * @param {string} filePath - Path to the file
 * @param {Object} typeConfig - File type configuration
 * @returns {string} The updated comment
 */
const updateExistingComment = (comment, filePath, typeConfig) => {
  const config = getConfig();

  if (typeConfig.style === "json") {
    // comment is already a parsed JSON object for JSON files
    const json = typeof comment === "string" ? JSON.parse(comment) : comment;
    if (!json._copyright) json._copyright = config.copyright;
    if (!json._license)
      json._license = "This software is licensed under the MIT License.";
    if (!json._file || json._file !== filePath) json._file = filePath;
    return JSON.stringify(json, null, 2);
  }

  const lines = comment.split("\n");
  let hasCopyright = false;
  let hasLicense = false;
  let hasFile = false;

  // Check existing lines and update file path if it exists
  lines.forEach((line, index) => {
    if (line.includes("Copyright")) hasCopyright = true;
    if (line.includes("License")) hasLicense = true;
    if (line.includes("File:")) {
      hasFile = true;
      lines[index] = `${
        typeConfig.linePrefix || ""
      } File: ${filePath}`.trimRight();
    }
  });

  // Find insertion point (after prefix line)
  const insertIndex =
    lines.findIndex((line) => line.trim().startsWith(typeConfig.prefix)) + 1;

  // Add missing lines
  if (!hasFile) {
    const fileLine = typeConfig.linePrefix
      ? `${typeConfig.linePrefix} File: ${filePath}`
      : `File: ${filePath}`;
    lines.splice(insertIndex, 0, fileLine);
  }
  if (!hasLicense) {
    const licenseLine = typeConfig.linePrefix
      ? `${typeConfig.linePrefix} This software is licensed under the MIT License.`
      : "This software is licensed under the MIT License.";
    lines.splice(insertIndex, 0, licenseLine);
  }
  if (!hasCopyright) {
    const copyrightLine = typeConfig.linePrefix
      ? `${typeConfig.linePrefix} ${config.copyright}`
      : config.copyright;
    lines.splice(insertIndex, 0, copyrightLine);
  }

  return lines.join("\n");
};

/**
 * Generates a complete new header for a file
 * @param {string} filePath - Path to the file
 * @param {Object} typeConfig - File type configuration
 * @param {string} content - Original file content
 * @returns {string} The generated header with content
 */
const generateCompleteHeader = (filePath, typeConfig, content) => {
  const config = getConfig();
  const aiAttrib =
    config.aiAttribution ||
    "This was generated by Claude Sonnet 3.5, with the assistance of my human mentor";

  if (typeConfig.style === "json") {
    try {
      const existingContent = JSON.parse(content);
      return JSON.stringify(
        {
          _copyright: config.copyright,
          _license: "This software is licensed under the MIT License.",
          _file: filePath,
          ...existingContent,
        },
        null,
        2
      );
    } catch {
      return content; // Return unchanged if JSON parsing fails
    }
  }

  const lines = [
    config.copyright,
    "This software is licensed under the MIT License.",
    `File: ${filePath}`,
    aiAttrib,
  ];

  // Generate the header
  let header;
  if (!typeConfig.linePrefix) {
    // For styles without line prefixes (markdown, html, python)
    header = `${typeConfig.prefix}\n${lines.join("\n")}\n${
      typeConfig.suffix
    }\n\n`;
  } else {
    // For styles with line prefixes (js, css)
    header = `${typeConfig.prefix}\n${lines
      .map((line) => `${typeConfig.linePrefix} ${line}`)
      .join("\n")}\n${typeConfig.suffix}\n\n`;
  }

  // Remove any existing header from the content
  const contentWithoutHeader = content
    .replace(/^\/\*\*[\s\S]*?\*\/\s*/, "")
    .replace(/^\/\*[\s\S]*?\*\/\s*/, "")
    .replace(/^<!--[\s\S]*?-->\s*/, "")
    .replace(/^"""[\s\S]*?"""\s*/, "");

  // Return header followed by the content
  return header + contentWithoutHeader;
};

/**
 * Adds or corrects the header of a file
 * @param {string} filePath - Path to the file
 * @param {string} content - Content of the file
 * @returns {string} The content with the correct header
 */
const addOrCorrectHeader = (filePath, content) => {
  const config = getConfig();
  const typeConfig = getFileTypeConfig(filePath, config);

  // Skip excluded files
  if (isExcludedFile(filePath, typeConfig)) {
    return content;
  }

  const initialComment = getInitialComment(content, typeConfig);
  if (!initialComment) {
    return generateCompleteHeader(filePath, typeConfig, content);
  }

  // Update existing header
  const updatedComment = updateExistingComment(
    initialComment,
    filePath,
    typeConfig
  );
  if (typeConfig.style === "json") {
    return updatedComment;
  }

  // Get the content after the initial comment
  const remainingContent = content.substring(initialComment.length);
  // Return updated header followed by the remaining content
  return updatedComment + remainingContent;
};

/**
 * Recursively gets all files in a directory
 * @param {string} dir - The directory to search
 * @returns {string[]} An array of file paths
 */
const getAllFiles = (dir) => {
  const files = fs.readdirSync(dir);
  let allFiles = [];
  for (const file of files) {
    const filePath = path.join(dir, file);
    if (fs.statSync(filePath).isDirectory()) {
      if (!config.skipFolders.includes(file)) {
        allFiles = allFiles.concat(getAllFiles(filePath));
      }
    } else {
      const ext = path.extname(file);
      // Check if this extension is handled by any file type
      const isHandled = Object.values(config.fileTypes).some((typeConfig) =>
        typeConfig.extensions.includes(ext)
      );
      if (isHandled) {
        allFiles.push(filePath);
      }
    }
  }
  return allFiles;
};

/**
 * Gets the grouping folder path based on maxNestingLevel
 * @param {string} filePath - The full path of the file
 * @param {string} basePath - The base output path
 * @param {number} maxNestingLevel - Maximum nesting level for grouping
 * @returns {string} The grouping folder path
 */
const getGroupingFolder = (filePath, basePath, maxNestingLevel) => {
  const relativePath = path.relative(basePath, filePath);
  const parts = relativePath.split(path.sep);

  if (parts.length <= maxNestingLevel) {
    return path.dirname(relativePath);
  }

  return parts.slice(0, maxNestingLevel).join(path.sep);
};

/**
 * Creates a backup of a file
 * @param {string} filePath - Path to the file to backup
 */
const backupFile = (filePath) => {
  const backupDir = path.join(config.outputFolder, config.backupFolder);
  if (!fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true });
  }
  const backupPath = path.join(backupDir, path.basename(filePath));
  fs.copyFileSync(filePath, backupPath);
};

/**
 * Concatenates files by their folder up to maxNestingLevel
 * @param {Object} config - The project packager configuration
 * @param {string} tempDir - Directory containing processed files
 * @param {string} outputPath - Final output directory for markdown files
 * @returns {Promise<void>}
 */
const concatenateOutputFiles = async (config, tempDir, outputPath) => {
  const allFiles = getAllFiles(tempDir);
  const maxNestingLevel = config.maxNestingLevel || 1;

  // Group files by their folder up to maxNestingLevel
  const filesByFolder = {};
  for (const file of allFiles) {
    const groupingFolder = getGroupingFolder(file, tempDir, maxNestingLevel);

    if (!filesByFolder[groupingFolder]) {
      filesByFolder[groupingFolder] = [];
    }
    filesByFolder[groupingFolder].push(file);
  }

  // Create output directory if it doesn't exist
  if (!fs.existsSync(outputPath)) {
    fs.mkdirSync(outputPath, { recursive: true });
  }

  // Create concatenated markdown file for each folder group
  for (const [folder, files] of Object.entries(filesByFolder)) {
    const concatenatedContent = [];
    const folderName = folder === "." ? "root" : folder;

    // Add folder title
    concatenatedContent.push(`# ${folderName}\n`);

    // Sort files to ensure consistent output
    files.sort((a, b) => a.localeCompare(b));

    for (const file of files) {
      const relativePath = path.relative(tempDir, file);
      const content = fs.readFileSync(file, "utf8");
      const extension = path.extname(file).slice(1); // remove the dot

      concatenatedContent.push(`## ${relativePath}\n`);
      concatenatedContent.push("```" + extension);
      concatenatedContent.push(content);
      concatenatedContent.push("```\n");
    }

    // Create sanitized folder name for the output file
    const sanitizedFolderName = folderName.replace(/[\/\\]/g, "-");
    const concatenatedPath = path.join(outputPath, `${sanitizedFolderName}.md`);
    fs.writeFileSync(concatenatedPath, concatenatedContent.join("\n"));

    // Log the creation
    console.log(
      `Created markdown file for ${folderName} at ${concatenatedPath}`
    );
  }
};

/**
 * Packages the project files
 */
const packageProject = async (args) => {
  console.log("Starting packageProject");
  const files = getAllFiles(process.cwd());
  const outputPath = path.join(process.cwd(), config.outputFolder);

  // Create temporary directory for processing if not expanding
  const tempDir = args.expand ? outputPath : path.join(outputPath, ".temp");

  console.log(`Found ${files.length} files to package`);

  // First, process all files individually
  files.forEach((file) => {
    console.log(`Processing file: ${file}`);
    const content = fs.readFileSync(file, "utf8");
    const packagedContent = addOrCorrectHeader(file, content);
    const outputFilePath = path.join(
      tempDir,
      path.relative(process.cwd(), file)
    );
    console.log(`Writing to: ${outputFilePath}`);
    fs.mkdirSync(path.dirname(outputFilePath), { recursive: true });
    fs.writeFileSync(outputFilePath, packagedContent);
  });

  // Then concatenate all files from the temporary directory
  await concatenateOutputFiles(config, tempDir, outputPath);

  // Clean up temporary directory if not expanding
  if (!args.expand) {
    if (fs.existsSync(tempDir)) {
      fs.rmSync(tempDir, { recursive: true, force: true });
    }
  }

  console.log("Project packaged and concatenated successfully.");
};

/**
 * Extracts a file's content from markdown code block
 * @param {string} block - The markdown code block content
 * @returns {{extension: string, content: string}} The file extension and content
 */
const extractFromCodeBlock = (block) => {
  const firstLine = block.split("\n")[0];
  const extension = firstLine.trim();
  const content = block.split("\n").slice(1).join("\n");
  return { extension, content };
};

/**
 * Processes a markdown file and extracts its files
 * @param {string} markdownPath - Path to the markdown file
 * @param {string} baseOutputPath - Base path for output files
 * @returns {Array<{path: string, content: string}>} Array of extracted files
 */
const processMarkdownFile = (markdownPath) => {
  const content = fs.readFileSync(markdownPath, "utf8");
  const files = [];

  // Get base folder name from markdown file name
  const baseFolderName = path.basename(markdownPath, ".md");
  const baseFolder =
    baseFolderName === "root" ? "." : baseFolderName.replace(/-/g, "/");

  // Split content into sections by ## headers
  const sections = content.split("\n## ");

  // Skip the first section as it's the # folder title
  for (let i = 1; i < sections.length; i++) {
    const section = sections[i];
    const lines = section.split("\n");

    // First line is the file path
    const relativePath = lines[0].trim();

    // Find the code block
    const codeBlockStart = lines.findIndex((line) => line.startsWith("```"));
    if (codeBlockStart === -1) continue;

    const codeBlockEnd =
      lines
        .slice(codeBlockStart + 1)
        .findIndex((line) => line.startsWith("```")) +
      codeBlockStart +
      1;
    if (codeBlockEnd === -1) continue;

    const codeBlock = lines.slice(codeBlockStart + 1, codeBlockEnd).join("\n");
    const { content } = extractFromCodeBlock(codeBlock);

    // Calculate the full path relative to the base folder
    const fullPath =
      baseFolder === "." ? relativePath : path.join(baseFolder, relativePath);

    files.push({ path: fullPath, content });
  }

  return files;
};

/**
 * Modified unpackageProject function that works with markdown format
 * @param {Object} args - Command line arguments
 */
const unpackageProject = async (args) => {
  console.log("Starting unpackageProject");
  const packagedFolder = path.join(process.cwd(), config.outputFolder);
  const outputBase = process.cwd();
  const tempDir = args.expand
    ? path.join(packagedFolder)
    : path.join(packagedFolder, ".temp");

  if (!fs.existsSync(packagedFolder)) {
    console.error(`Package folder ${packagedFolder} does not exist`);
    process.exit(1);
  }

  // Find all markdown files
  const markdownFiles = fs
    .readdirSync(packagedFolder)
    .filter((file) => file.endsWith(".md"))
    .map((file) => path.join(packagedFolder, file));

  console.log(`Found ${markdownFiles.length} markdown files to process`);

  // Process each markdown file
  for (const mdFile of markdownFiles) {
    console.log(`Processing ${mdFile}...`);
    const files = processMarkdownFile(mdFile);

    // Write each file
    for (const { path: filePath, content } of files) {
      // Write to original location
      const originalPath = path.join(outputBase, filePath);
      console.log(`Writing to: ${originalPath}`);
      fs.mkdirSync(path.dirname(originalPath), { recursive: true });
      fs.writeFileSync(originalPath, content);

      // If expand is true, also write to package directory
      if (args.expand) {
        const packagePath = path.join(tempDir, filePath);
        console.log(`Writing to package: ${packagePath}`);
        fs.mkdirSync(path.dirname(packagePath), { recursive: true });
        fs.writeFileSync(packagePath, content);
      }
    }
  }

  console.log("Project unpackaged successfully.");
};

/**
 * Runs the project tests
 * @param {boolean} watch - Whether to run tests in watch mode
 */
const runTests = (watch = true) => {
  try {
    console.log(watch ? "Running tests in watch mode..." : "Running tests...");
    const watchFlag = watch ? "--watch" : "";
    const jestCommand = `jest ${watchFlag} --testPathPattern=projectPackager`;
    execSync(jestCommand, { stdio: "inherit" });
    console.log("Test run completed successfully.");
  } catch (error) {
    console.error("Some tests failed.");
    process.exit(1);
  }
};

/**
 * Parses command line arguments
 * @returns {Object} Parsed arguments
 */
const parseArgs = () => {
  // Reset argv to ensure fresh parsing each time
  argv = null;
  return yargs(hideBin(process.argv))
    .option("verbose", {
      alias: "v",
      type: "boolean",
      description: "Run with verbose logging",
    })
    .option("unpackage", {
      alias: "u",
      type: "boolean",
      description: "Unpackage previously packaged files",
    })
    .option("expand", {
      alias: "e",
      type: "boolean",
      default: false,
      description:
        "Expland the files being packaged into the ouptput directory",
    })
    .option("test", {
      alias: "t",
      type: "boolean",
      description: "Run unit tests",
    })
    .option("watch", {
      type: "boolean",
      default: true,
      description: "Run tests in watch mode",
    })
    .option("configPath", {
      type: "string",
      default: "scripts/projectPackager.json",
      description: "Path to the configuration file",
    })
    .parse();
};

/**
 * Main function to run the project packager
 */
const main = () => {
  const args = parseArgs();
  loadConfig(args.configPath);

  if (args.test) {
    runTests(args.watch);
  } else if (args.unpackage) {
    unpackageProject();
  } else {
    packageProject(args);
  }
};

// Run the main function if this script is executed directly
if (require.main === module) {
  main();
}

module.exports = {
  loadConfig,
  getConfig,
  getFileTypeConfig,
  getInitialComment,
  generateCompleteHeader,
  updateExistingComment,
  addOrCorrectHeader,
  isExcludedFile,
  getAllFiles,
  getGroupingFolder,
  backupFile,
  packageProject,
  unpackageProject,
  runTests,
  parseArgs,
  main,
};

```

## scripts/projectPackager.json

```json
{
  "_copyright": "Copyright (c) 2024 Martin Bechard <martin.bechard@DevConsult.ca>",
  "_license": "This software is licensed under the MIT License.",
  "_file": "/Users/martinbechard/dev/projectPackager/scripts/projectPackager.json",
  "outputFolder": "project",
  "skipFolders": [
    "node_modules",
    "project",
    ".next",
    ".git",
    "logs",
    "data",
    "test_runs"
  ],
  "fileTypes": {
    "js": {
      "extensions": [
        ".js",
        ".ts",
        ".tsx",
        ".jsx"
      ],
      "style": "block",
      "prefix": "/**",
      "linePrefix": " *",
      "suffix": " */"
    },
    "json": {
      "extensions": [
        ".json"
      ],
      "style": "json",
      "attributes": [
        "_copyright",
        "_license",
        "_file"
      ],
      "exclude": [
        "package.json",
        "package-lock.json",
        "tsconfig.json"
      ]
    },
    "md": {
      "extensions": [
        ".md"
      ],
      "style": "markdown",
      "prefix": "<!--",
      "linePrefix": "",
      "suffix": "-->"
    },
    "css": {
      "extensions": [
        ".css"
      ],
      "style": "block",
      "prefix": "/*",
      "linePrefix": " *",
      "suffix": "*/"
    },
    "html": {
      "extensions": [
        ".html"
      ],
      "style": "html",
      "prefix": "<!--",
      "linePrefix": "",
      "suffix": "-->"
    },
    "py": {
      "extensions": [
        ".py"
      ],
      "style": "block",
      "prefix": "\"\"\"",
      "linePrefix": "",
      "suffix": "\"\"\""
    }
  },
  "copyright": "Copyright (c) 2024 Martin Bechard <martin.bechard@DevConsult.ca>",
  "backupFolder": "backups",
  "maxNestingLevel": 1
}
```

## scripts/projectPackager.test.js

```js
/**
 * Copyright (c) 2024 Martin Bechard <martin.bechard@DevConsult.ca>
 * This software is licensed under the MIT License.
 * File: /Users/martinbechard/dev/projectPackager/scripts/projectPackager.test.js
 * This was generated by Claude Sonnet 3.5, with the assistance of my human mentor
 * Summary: Comprehensive test suite for the Project Packager utility
 * Witty remark: Testing a packager? It's like quality control for your quality control!
 */

const fs = require("fs");
const path = require("path");
const childProcess = require("child_process");

// Mock modules
jest.mock("fs");
jest.mock("path");
jest.mock("child_process");

/**
 * Mock config
 * Assumptions:
 * 1. The config structure matches the expected format in projectPackager.js
 * 2. It includes necessary fields like outputFolder, skipFolders, fileTypes, etc.
 * 3. Copyright and AI attribution are included for header generation
 * Rationale: This mock config allows us to test config-dependent functionality
 * without relying on an external config file.
 */
const mockConfig = {
  outputFolder: "claude",
  skipFolders: ["node_modules", "claude", ".next", ".git"],
  fileTypes: {
    js: [".js", ".ts", ".tsx"],
    json: [".json"],
    md: [".md"],
    css: [".css"],
    html: [".html"],
  },
  copyright: "Copyright (c) 2024 Martin Bechard <martin.bechard@DevConsult.ca>",
  aiAttribution:
    "This was generated by Claude Sonnet 3.5, with the assistance of my human mentor",
  backupFolder: "backups",
};

/**
 * Mock file system
 * Assumptions:
 * 1. The root directory is /mock/cwd
 * 2. There are files in the root and a subfolder
 * 3. There's a 'claude' folder for packaged files
 * 4. The config file is in the scripts folder
 * Rationale: This structure mimics a typical project layout, allowing us to test
 * various file operations and directory traversals.
 */
const mockFs = {
  "/mock/cwd/file1.js": "const a = 1;",
  "/mock/cwd/file2.js": "const b = 2;",
  "/mock/cwd/subfolder/file3.js": "const c = 3;",
  "/mock/cwd/scripts/projectPackager.json": JSON.stringify(mockConfig),
  "/mock/cwd/claude/packaged_file1.js": "/* Packaged content */",
  "/mock/cwd/claude/packaged_file2.js": "/* Packaged content */",
};

/**
 * Mock fs module
 * Assumptions:
 * 1. readFileSync can handle both absolute and relative paths
 * 2. writeFileSync updates the mock file system
 * 3. existsSync checks for file existence in the mock file system
 * 4. readdirSync returns files and folders in a given directory
 * 5. statSync determines if a path is a file or directory
 * Rationale: These mocks allow us to simulate file system operations without
 * touching the actual file system, providing a controlled test environment.
 */
fs.readFileSync.mockImplementation((filePath) => {
  const absolutePath = path.isAbsolute(filePath)
    ? filePath
    : path.join("/mock/cwd", filePath);
  if (mockFs[absolutePath]) {
    return mockFs[absolutePath];
  }
  throw new Error(`ENOENT: no such file or directory, open '${filePath}'`);
});

fs.writeFileSync.mockImplementation((filePath, content) => {
  const absolutePath = path.isAbsolute(filePath)
    ? filePath
    : path.join("/mock/cwd", filePath);
  mockFs[absolutePath] = content;
});

fs.existsSync.mockImplementation((filePath) => {
  const absolutePath = path.isAbsolute(filePath)
    ? filePath
    : path.join("/mock/cwd", filePath);
  return !!mockFs[absolutePath];
});

fs.readdirSync.mockImplementation((dir) => {
  const normalizedDir = path.normalize(dir);
  const absoluteDir = path.isAbsolute(normalizedDir)
    ? normalizedDir
    : path.join("/mock/cwd", normalizedDir);
  const files = Object.keys(mockFs)
    .filter((file) => file.startsWith(absoluteDir) && file !== absoluteDir)
    .map((file) => path.basename(file));
  return [...new Set(files)]; // Remove duplicates
});

fs.statSync.mockImplementation((filePath) => {
  const absolutePath = path.isAbsolute(filePath)
    ? filePath
    : path.join("/mock/cwd", filePath);
  return {
    isDirectory: () =>
      !mockFs[absolutePath] || !mockFs[absolutePath].includes("="),
  };
});

fs.copyFileSync.mockImplementation((src, dest) => {
  const absoluteSrc = path.isAbsolute(src) ? src : path.join("/mock/cwd", src);
  const absoluteDest = path.isAbsolute(dest)
    ? dest
    : path.join("/mock/cwd", dest);
  mockFs[absoluteDest] = mockFs[absoluteSrc];
});

/**
 * Mock path module
 * Assumptions:
 * 1. join concatenates path segments
 * 2. resolve resolves paths to absolute form
 * 3. relative calculates relative paths
 * 4. isAbsolute checks if a path is absolute
 * Rationale: These mocks ensure consistent path handling across different platforms.
 */
path.join.mockImplementation((...args) => args.join("/"));
path.resolve.mockImplementation((...args) => "/" + args.join("/"));
path.relative.mockImplementation((from, to) => {
  const fromParts = from.split("/").filter(Boolean);
  const toParts = to.split("/").filter(Boolean);
  while (
    fromParts.length > 0 &&
    toParts.length > 0 &&
    fromParts[0] === toParts[0]
  ) {
    fromParts.shift();
    toParts.shift();
  }
  return [...Array(fromParts.length).fill(".."), ...toParts].join("/");
});
path.isAbsolute.mockImplementation((p) => p.startsWith("/"));

/**
 * Mock process
 * Assumptions:
 * 1. The current working directory is /mock/cwd
 * 2. argv can be manipulated for testing different command-line arguments
 * Rationale: This allows us to simulate different execution environments and test
 * command-line argument handling.
 */
const mockProcess = {
  argv: ["node", "/path/to/script.js"],
  env: {},
  cwd: jest.fn(() => "/mock/cwd"),
  exit: jest.fn(),
};
jest.mock("process", () => mockProcess);

/**
 * Mock yargs
 * Assumptions:
 * 1. The parse method processes argv and returns an object with parsed arguments
 * 2. Default values are provided for all possible arguments
 * Rationale: This allows us to test different command-line argument scenarios without
 * actually using the yargs library.
 */
const mockYargsInstance = {
  option: jest.fn().mockReturnThis(),
  help: jest.fn().mockReturnThis(),
  alias: jest.fn().mockReturnThis(),
  parse: jest.fn(() => {
    const result = {
      verbose: false,
      dumpFileMap: false,
      addMissingComments: false,
      unpackage: false,
      test: true,
      generateFileTree: false,
      watch: true,
      configPath: "scripts/projectPackager.json",
      outputFolder: "claude",
    };
    mockProcess.argv.forEach((arg) => {
      if (arg.startsWith("--")) {
        const [key, value] = arg.slice(2).split("=");
        result[key] =
          value === "false" ? false : value === "true" ? true : value || true;
      }
    });
    return result;
  }),
};

const mockYargs = jest.fn(() => mockYargsInstance);
jest.mock("yargs/yargs", () => mockYargs);

// Mock yargs helpers
jest.mock("yargs/helpers", () => ({
  hideBin: jest.fn((arr) => arr.slice(2)),
}));

// Import the module under test
const projectPackager = require("../scripts/projectPackager");

describe("Project Packager", () => {
  beforeEach(() => {
    jest.clearAllMocks();
    mockProcess.argv = ["node", "/path/to/script.js"];
    projectPackager.loadConfig("scripts/projectPackager.json");
  });

  describe("Config Loading", () => {
    /**
     * Test: loadConfig loads the config file correctly
     * Constraints:
     * - The config file must exist in the mock file system at /mock/cwd/scripts/projectPackager.json
     * - The content of the config file must match mockConfig
     */
    test("loadConfig loads the config file correctly", () => {
      expect(() =>
        projectPackager.loadConfig("scripts/projectPackager.json")
      ).not.toThrow();
    });

    /**
     * Test: loadConfig sets the correct config values
     * Constraints:
     * - The loaded config must match mockConfig
     */
    test("loadConfig sets the correct config values", () => {
      projectPackager.loadConfig("scripts/projectPackager.json");
      expect(projectPackager.getConfig()).toEqual(mockConfig);
    });

    /**
     * Test: loadConfig throws an error for non-existent config file
     * Constraints:
     * - The specified config file must not exist in the mock file system
     */
    test("loadConfig throws an error for non-existent config file", () => {
      expect(() => projectPackager.loadConfig("non-existent.json")).toThrow();
    });
  });

  describe("Header Checks", () => {
    /**
     * Test: hasCorrectHeader identifies correct headers
     * Constraints:
     * - The header must contain the copyright and AI attribution from mockConfig
     */
    test("hasCorrectHeader identifies correct headers", () => {
      const correctHeader = `/**
 * Copyright (c) 2024 Martin Bechard <martin.bechard@DevConsult.ca>
 * This software is licensed under the MIT License.
 * File: test/file.js
 * This was generated by Claude Sonnet 3.5, with the assistance of my human mentor
 */

const x = 1;`;
      expect(
        projectPackager.hasCorrectHeader("test/file.js", correctHeader)
      ).toBe(true);
    });

    /**
     * Test: hasCorrectHeader identifies incorrect headers
     * Constraints:
     * - The header must not match the expected format
     */
    test("hasCorrectHeader identifies incorrect headers", () => {
      const incorrectHeader = `/**
 * Wrong copyright
 * No license
 * File: test/file.js
 */

const x = 1;`;
      expect(
        projectPackager.hasCorrectHeader("test/file.js", incorrectHeader)
      ).toBe(false);
    });

    /**
     * Test: generateHeader creates correct headers
     * Constraints:
     * - The generated header must contain the copyright and AI attribution from mockConfig
     */
    test("generateHeader creates correct headers", () => {
      const expectedHeader = `/**
 * Copyright (c) 2024 Martin Bechard <martin.bechard@DevConsult.ca>
 * This software is licensed under the MIT License.
 * File: test/file.js
 * This was generated by Claude Sonnet 3.5, with the assistance of my human mentor
 */

`;
      expect(projectPackager.generateHeader("test/file.js")).toBe(
        expectedHeader
      );
    });

    /**
     * Test: addOrCorrectHeader adds header to files without one
     * Constraints:
     * - The input content must not have a header
     * - The output content must have the correct header prepended
     */
    test("addOrCorrectHeader adds header to files without one", () => {
      const content = "const x = 1;";
      const expectedContent =
        projectPackager.generateHeader("test/file.js") + content;
      expect(projectPackager.addOrCorrectHeader("test/file.js", content)).toBe(
        expectedContent
      );
    });

    /**
     * Test: addOrCorrectHeader corrects incorrect headers
     * Constraints:
     * - The input content must have an incorrect header
     * - The output content must have the correct header
     */
    test("addOrCorrectHeader corrects incorrect headers", () => {
      const incorrectHeader = `/**
 * Wrong header
 */

const x = 1;`;
      const expectedContent =
        projectPackager.generateHeader("test/file.js") + "const x = 1;";
      expect(
        projectPackager.addOrCorrectHeader("test/file.js", incorrectHeader)
      ).toBe(expectedContent);
    });
  });

  describe("Project Packaging", () => {
    /**
     * Test: packageProject processes files correctly
     * Constraints:
     * - The mock file system must contain files to package
     * - fs.writeFileSync must be called for each packaged file
     * - Packaged files must be written to the claude folder in the mock file system
     */
    test("packageProject processes files correctly", () => {
      projectPackager.packageProject();
      expect(fs.writeFileSync).toHaveBeenCalled();
      expect(fs.writeFileSync.mock.calls[0][0]).toContain("claude");

      expect(mockFs["/mock/cwd/claude/file1.js"]).toBeDefined();
      expect(mockFs["/mock/cwd/claude/file2.js"]).toBeDefined();
      expect(mockFs["/mock/cwd/claude/subfolder/file3.js"]).toBeDefined();
    });

    /**
     * Test: unpackageProject extracts files correctly
     * Constraints:
     * - The mock file system must contain packaged files in the claude folder
     * - fs.writeFileSync must be called for each unpackaged file
     * - Unpackaged files must be written back to their original locations in the mock file system
     */
    test("unpackageProject extracts files correctly", () => {
      mockFs["/mock/cwd/claude/packaged_file1.js"] = "/* Packaged content 1 */";
      mockFs["/mock/cwd/claude/packaged_file2.js"] = "/* Packaged content 2 */";

      projectPackager.unpackageProject();
      expect(fs.writeFileSync).toHaveBeenCalled();

      expect(mockFs["/mock/cwd/packaged_file1.js"]).toBeDefined();
      expect(mockFs["/mock/cwd/packaged_file2.js"]).toBeDefined();
    });

    /**
     * Test: saveFileTree generates and saves file tree
     * Constraints:
     * - fs.writeFileSync must be called with the correct file path and content
     * - The file tree must be written to the claude folder in the mock file system
     */
    test("saveFileTree generates and saves file tree", () => {
      projectPackager.saveFileTree();
      expect(fs.writeFileSync).toHaveBeenCalledWith(
        path.join(mockConfig.outputFolder, "fileTree.md"),
        expect.stringContaining("Project File Tree")
      );

      expect(mockFs["/mock/cwd/claude/fileTree.md"]).toBeDefined();
    });
  });

  describe("Test Running", () => {
    /**
     * Test: runTests executes Jest correctly with watch mode as default
     * Constraints:
     * - childProcess.execSync must be called with the correct Jest command
     * - The command must include the --watch flag
     */
    test("runTests executes Jest correctly with watch mode as default", () => {
      const mockExecSync = jest.fn();
      childProcess.execSync.mockImplementation(mockExecSync);
      projectPackager.runTests();
      expect(mockExecSync).toHaveBeenCalledWith(
        expect.stringContaining(
          "jest --watch --testPathPattern=projectPackager"
        ),
        expect.anything()
      );
    });

    /**
     * Test: runTests executes Jest correctly without watch mode when specified
     * Constraints:
     * - childProcess.execSync must be called with the correct Jest command
     * - The command must not include the --watch flag
     */
    test("runTests executes Jest correctly without watch mode when specified", () => {
      const mockExecSync = jest.fn();
      childProcess.execSync.mockImplementation(mockExecSync);
      projectPackager.runTests(false);
      expect(mockExecSync).toHaveBeenCalledWith(
        expect.stringMatching(
          /jest(?!\s+--watch)\s+--testPathPattern=projectPackager/
        ),
        expect.anything()
      );
    });
  });

  describe("Utility Functions", () => {
    /**
     * Test: backupFile creates a backup correctly
     * Constraints:
     * - fs.copyFileSync must be called with the correct source and destination paths
     * - The destination path must include the backupFolder from mockConfig
     */
    test("backupFile creates a backup correctly", () => {
      projectPackager.backupFile("test/file.js");
      expect(fs.copyFileSync).toHaveBeenCalledWith(
        "test/file.js",
        expect.stringContaining("backups")
      );
    });
  });

  describe("Command Line Argument Parsing", () => {
    /**
     * Test: parseArgs returns correct default values
     * Constraints:
     * - The mock process.argv must not contain any custom arguments
     * - The returned args object must match the default values in mockYargsInstance
     */
    test("parseArgs returns correct default values", () => {
      const args = projectPackager.parseArgs();
      expect(args.watch).toBe(true);
      expect(args.configPath).toBe("scripts/projectPackager.json");
    });

    /**
     * Test: parseArgs handles custom arguments correctly
     * Constraints:
     * - The mock process.argv must be set with custom arguments
     * - The returned args object must reflect the custom arguments
     */
    test("parseArgs handles custom arguments correctly", () => {
      mockProcess.argv = [
        "node",
        "/path/to/script.js",
        "--watch=false",
        "--configPath=custom.json",
      ];
      const args = projectPackager.parseArgs();
      expect(args.watch).toBe(false);
      expect(args.configPath).toBe("custom.json");
    });

    /**
     * Test: parseArgs handles boolean flags correctly
     * Constraints:
     * - The mock process.argv must be set with boolean flags
     * - The returned args object must correctly interpret boolean flags
     */
    test("parseArgs handles boolean flags correctly", () => {
      mockProcess.argv = [
        "node",
        "/path/to/script.js",
        "--verbose",
        "--dumpFileMap",
      ];
      const args = projectPackager.parseArgs();
      expect(args.verbose).toBe(true);
      expect(args.dumpFileMap).toBe(true);
    });

    /**
     * Test: parseArgs handles mixed types of arguments
     * Constraints:
     * - The mock process.argv must be set with a mix of boolean flags and key-value pairs
     * - The returned args object must correctly interpret all argument types
     */
    test("parseArgs handles mixed types of arguments", () => {
      mockProcess.argv = [
        "node",
        "/path/to/script.js",
        "--watch=false",
        "--verbose",
        "--configPath=custom.json",
      ];
      const args = projectPackager.parseArgs();
      expect(args.watch).toBe(false);
      expect(args.verbose).toBe(true);
      expect(args.configPath).toBe("custom.json");
    });
  });
});

describe("Mock Function Tests", () => {
  describe("path.relative mock", () => {
    /**
     * Test: correctly calculates relative path
     * Constraints:
     * - The mock path.relative function must handle various path scenarios
     */
    test("correctly calculates relative path", () => {
      expect(path.relative("/a/b/c", "/a/d/e")).toBe("../../d/e");
      expect(path.relative("/a/b", "/a/b/c/d")).toBe("c/d");
      expect(path.relative("/a/b/c", "/a/b/c")).toBe("");
      expect(path.relative("/a/b/c", "/d/e/f")).toBe("../../../d/e/f");
    });
  });

  describe("fs.readFileSync mock", () => {
    /**
     * Test: returns correct content for existing files
     * Constraints:
     * - The mock file system must contain the files being read
     * - The mock fs.readFileSync must return the correct content for each file
     */
    test("returns correct content for existing files", () => {
      expect(fs.readFileSync("scripts/projectPackager.json")).toBe(
        JSON.stringify(mockConfig)
      );
      expect(fs.readFileSync("/mock/cwd/file1.js")).toBe("const a = 1;");
    });

    /**
     * Test: throws error for non-existent files
     * Constraints:
     * - The mock file system must not contain the file being read
     * - The mock fs.readFileSync must throw an ENOENT error for non-existent files
     */
    test("throws error for non-existent files", () => {
      expect(() => fs.readFileSync("non-existent.js")).toThrow(
        "ENOENT: no such file or directory, open 'non-existent.js'"
      );
    });
  });

  describe("yargs mock", () => {
    /**
     * Test: parses arguments correctly
     * Constraints:
     * - The mock process.argv must be set with test arguments
     * - The mock yargs parse function must correctly interpret the arguments
     */
    test("parses arguments correctly", () => {
      const yargsInstance = mockYargs();
      mockProcess.argv = [
        "node",
        "/path/to/script.js",
        "--watch=false",
        "--configPath=custom.json",
      ];
      const result = yargsInstance.parse();
      expect(result.watch).toBe(false);
      expect(result.configPath).toBe("custom.json");
    });
  });
});

```
